---
title: "Cleaning_DVF"
author: "Paul"
format: html
---


# !! IMMPORTANT !! 
If you want to replicate our data you can either download the DVF file from : 
<https://www.data.gouv.fr/datasets/demandes-de-valeurs-foncieres-geolocalisees> 
This file is quite big (3,5Go) so we werent able to upload it on Git, so you can also use the reduced version you can find in DATA_RAW "DVF_Paris_2020_25.rds" this is the same one but reduced to the Paris region and with the good columns. If you're starting from the second option you can skip the next three parts and continue from "Buildind a Price/squaremeter indicator".


#First DVf database (2020-1stSemester2025)
```{r}
library(data.table)
library(sf)
library(dplyr)
library(here)
```

#Keeping the departements we want to look at, same for the columns 
```{r}
Paris <- c("75")


cols_keep <- c(
  "id_mutation",
  "date_mutation",
  "nature_mutation",
  "valeur_fonciere",
  "type_local",
  "code_type_local",
  "surface_reelle_bati",
  "nombre_pieces_principales",
  "surface_terrain",
  "code_postal",
  "code_commune",
  "nom_commune",
  "longitude",
  "latitude",
  "id_parcelle",
  "code_departement"
)

```


#Getting rid of problematic data 
```{r}
DVF_Paris_2020_25 <- fread(
  here("DATA_Raw", "dvf.csv"),
  select = cols_keep
)[
  code_departement %in% Paris &
    type_local %in% c("Appartement", "Maison") &
    !is.na(surface_reelle_bati) &
    surface_reelle_bati > 9 & surface_reelle_bati < 500 &
    valeur_fonciere > 5000 & valeur_fonciere < 5e6 &
    !is.na(longitude) & !is.na(latitude)
]

saveRDS(
  DVF_Paris_2020_25,
  here("DATA_Raw", "DVF_Paris_2020_25.rds")
)

```


#Building a Price/Squaremeter indicator
```{r}
DVF_Paris_2020_25 <- readRDS(here("DATA_Raw", "DVF_Paris_2020_25.rds"))
DVF_Paris_2020_25[, prix_m2 := valeur_fonciere / surface_reelle_bati]


q <- quantile(DVF_Paris_2020_25$prix_m2, probs = c(0.015, 0.95), na.rm = TRUE)

DVF_Paris_2020_25 <- DVF_Paris_2020_25[
  prix_m2 >= q[1] & prix_m2 <= q[2]
]

```


#Spatial reattchement 
#transforming in lambert 93 (iris format)
```{r}
dvf_sf <- st_as_sf(
  DVF_Paris_2020_25,
  coords = c("longitude", "latitude"),
  crs = 4326              
) |>
  st_transform(2154)      
```

#loading up iris shape file of 2020
```{r}

iris2020 <- st_read(
  here(
    "DATA_Raw",
    "CONTOURS-IRIS_2-1_SHP_LAMB93_FXX-2020",
    "CONTOURS-IRIS.shp"
  ),
  quiet = TRUE
) |>
  st_transform(2154)

names(iris2020)


```
```{r}
dvf_iris <- st_join(
  dvf_sf,
  iris2020[, c("CODE_IRIS", "NOM_IRIS")],   
  left = TRUE
)


dvf_iris <- dvf_iris |> 
  filter(!is.na(CODE_IRIS))

```


```{r}
dvf_iris <- dvf_iris |>
  mutate(
    annee = as.integer(format(as.Date(date_mutation), "%Y"))
  )

```

```{r}

prix_iris_2020_25 <- dvf_iris |>
  st_drop_geometry() |>
  group_by(CODE_IRIS, annee) |>
  summarise(
    prix_m2_med  = median(prix_m2, na.rm = TRUE),
    prix_m2_mean = mean(prix_m2, na.rm = TRUE),
    n_ventes     = n(),
    .groups = "drop"
  ) |>
  filter(n_ventes >= 5)



saveRDS(
  prix_iris_2020_25,
  here("DATA_Processed", "prix_iris_2020_25.rds")
)
```

```{r}
nrow(prix_iris_2020_25)               
length(unique(prix_iris_2020_25$CODE_IRIS))  
sort(unique(prix_iris_2020_25$annee))        
```

#DVF 2014-2018




```{r}
library(dplyr)
library(stringr)
library(sf)
library(banR)
library(here)

```
#Loading IRIS
```{r}
iris2020 <- st_read(
  here("DATA_Raw", "CONTOURS-IRIS_2-1_SHP_LAMB93_FXX-2020", "CONTOURS-IRIS.shp"),
  quiet = TRUE
) |>
  st_transform(2154)
```

# !! IMMPORTANT !! 
Similar message than before if you want to replicate our data you can either download the DVF file from : 
<https://data.cquest.org/dgfip_dvf/> click on dvf-2014-2018.csv.gz 
This file is also quite big (2go) so we weren't able to upload it on Git, so you can also use the reduced version you can find in DATA_RAW "DVF_Paris_2014_18.rds" this is the same one but reduced to the Paris region and with the good columns + our built in adresses. If you're starting from the second option you can skip the next three parts and continue from "Building a Price/square meter indicator".


#Keeping the departement we want to look at, same for the columns (some differ from 2020)
```{r}

Paris <- c("75")
cols_keep2 <- c(
  "date_mutation",
  "nature_mutation",
  "valeur_fonciere",
  "type_local",
  "code_type_local",
  "surface_relle_bati",
  "nombre_pieces_principales",
  "surface_terrain",
  "code_postal",
  "code_commune",
  "commune",
  "code_departement",
  "numero_voie",
  "suffixe_numero",
  "type_voie",
  "voie"
)


```

#Loading 2014-18 data while getting rid of outliers 
```{r}

DVF_Paris_2014_18 <- fread(
  here("DATA_Raw", "dvf_14_18.csv"),
  select = cols_keep2
)[
  code_departement %in% Paris &
    type_local %in% c("Appartement", "Maison") &
    !is.na(surface_relle_bati) &
    surface_relle_bati > 9 & surface_relle_bati < 500 &
    valeur_fonciere > 5000 & valeur_fonciere < 5e6 
]


```

#Creating adresses for reverse geocoding 
```{r}
DVF_Paris_2014_18 <- DVF_Paris_2014_18 |>
  mutate(
    code_postal = if_else(
      is.na(code_postal),
      paste0(
        "750",
        str_pad(as.character(as.numeric(code_commune) %% 100), 2, pad = "0")
      ),
      as.character(code_postal)
    )
  ) |>
  filter(!is.na(code_postal)) |>
  mutate(
    adresse = str_squish(paste(
      numero_voie,
      suffixe_numero,
      type_voie,
      voie,
      code_postal,
      "Paris"
    ))
  )
saveRDS(
  DVF_Paris_2014_18,
  here("DATA_Raw", "DVF_Paris_2014_18.rds")
)
```

#Building a Price/Squaremeter indicator
```{r}
DVF_Paris_2014_18 <-readRDS(here("DATA_Raw", "DVF_Paris_2014_18.rds"))
DVF_Paris_2014_18[, prix_m2 := valeur_fonciere / surface_relle_bati]

q <- quantile(DVF_Paris_2014_18$prix_m2, probs = c(0.015, 0.95), na.rm = TRUE)

DVF_Paris_2014_18 <- DVF_Paris_2014_18[
  prix_m2 >= q[1] & prix_m2 <= q[2]
]
```


#Seperating unique adresses
```{r}
adresses_uniques <-  DVF_Paris_2014_18 |>
  distinct(adresse)
```

#Finding position and keeping the reliable ones 
```{r}
geo <- geocode_tbl(adresses_uniques, adresse)
geo <- geo |> filter(result_score >= 0.6)

```

#adding those positions to our previous base
```{r}
dvf_geo <-  DVF_Paris_2014_18 |>
  left_join(geo, by = "adresse") |>
  filter(!is.na(longitude) & !is.na(latitude))
```

#transform to correct format
```{r}
dvf_sf <- st_as_sf(dvf_geo, coords = c("longitude", "latitude"), crs = 4326) |>
  st_transform(2154)
```

#Link IRISES 
```{r}
dvf_iris_2014_18 <- st_join(
  dvf_sf,
  iris2020[, c("CODE_IRIS", "NOM_IRIS")],
  left = TRUE
) |>
  filter(!is.na(CODE_IRIS))

dvf_iris_2014_18 <- dvf_iris_2014_18 |>
  mutate(annee = as.integer(format(as.Date(date_mutation), "%Y")))
```


```{r}
prix_iris_2014_18 <- dvf_iris_2014_18 |>
  st_drop_geometry() |>
  group_by(CODE_IRIS, annee) |>
  summarise(
    prix_m2_med = median(prix_m2, na.rm = TRUE),
    prix_m2_mean = mean(prix_m2, na.rm = TRUE),
    n_ventes    = n(),
    .groups = "drop"
  ) |>
  filter(n_ventes >= 5)

```


#Save final 
```{r}
saveRDS(
  prix_iris_2014_18,
  here("DATA_Processed", "prix_iris_2014_18.rds")
)
```




#FInal step of cleaning mergin both bases into a final one 

```{r}

prix_2014_18 <- readRDS(here("DATA_Processed", "prix_iris_2014_18.rds"))
prix_2020_25 <- readRDS(here("DATA_Processed", "prix_iris_2020_25.rds"))

colnames(prix_2014_18)
colnames(prix_2020_25)



```

```{r}
prix_iris_2014_25 <- bind_rows(prix_2014_18, prix_2020_25) %>%
  arrange(CODE_IRIS, annee)


nrow(prix_iris_2014_25)
length(unique(prix_iris_2014_25$CODE_IRIS))
sort(unique(prix_iris_2014_25$annee))

```

```{r}
# Sauvegarde
saveRDS(prix_iris_2014_25, here("DATA_Processed", "prix_iris_2014_25.rds"))
```

